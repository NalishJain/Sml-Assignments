{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Id is :  1 number  of points are  70\n",
      "Cluster Id is :  2 number  of points are  76\n",
      "Cluster Id is :  3 number  of points are  17\n",
      "Cluster Id is :  5 number  of points are  13\n",
      "Cluster Id is :  6 number  of points are  9\n",
      "Cluster Id is :  7 number  of points are  29\n"
     ]
    }
   ],
   "source": [
    "def generateDataSet(csvFile):\n",
    "    dataSet = []\n",
    "    clusters = {}\n",
    "    with open(csvFile, 'r') as csvfile:\n",
    "        csvR = csv.reader(csvfile, delimiter = ',')\n",
    "        for data in csvR:\n",
    "            dataEntry = []\n",
    "            for i in range(0, len(data)-1):\n",
    "                dataEntry.append(float(data[i]))\n",
    "            if(int(data[len(data)-1]) not in clusters):\n",
    "                clusters[int(data[len(data)-1])] = []\n",
    "                clusters[int(data[len(data)-1])].append(dataEntry)\n",
    "            else:\n",
    "                clusters[int(data[len(data)-1])].append(dataEntry)\n",
    "            dataSet.append(dataEntry)\n",
    "    return np.array(dataSet), clusters\n",
    "\n",
    "dataSet, clusters = generateDataSet(\"glass.csv\")\n",
    "\n",
    "for i in clusters:\n",
    "    print(\"Cluster Id is : \", i, \"number  of points are \", len(clusters[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAHALNOBIS DISTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 9)\n",
      "2.593694328961828\n",
      "(214,)\n"
     ]
    }
   ],
   "source": [
    "def mahalnobisDistance(dataSet):\n",
    "    distance = []\n",
    "    meanXi = np.mean(dataSet, axis = 0)\n",
    "    covX = np.cov(dataSet.astype(float), rowvar = False)\n",
    "    invCovX = np.linalg.inv(covX)\n",
    "    for Xi in dataSet:\n",
    "        XiSubtractedMean = Xi - meanXi\n",
    "        mul1 = np.dot(XiSubtractedMean, invCovX)\n",
    "        mDistance = np.dot(mul1, XiSubtractedMean.T)\n",
    "        distance.append(abs(mDistance)**0.5)\n",
    "        # break\n",
    "    return np.array(distance)\n",
    "print(dataSet.shape)\n",
    "mahalNobisDistances = mahalnobisDistance(dataSet)\n",
    "print(np.mean(mahalNobisDistances))\n",
    "print(mahalNobisDistances.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0199705256087903\n",
      "1.9107859079361083\n",
      "(214,)\n"
     ]
    }
   ],
   "source": [
    "class LOF:\n",
    "    def __init__(self, dataSet, k):\n",
    "        self.dataSet = dataSet\n",
    "        self.k = k\n",
    "        self.kThDistance = []\n",
    "        self.kNearestNbrs = []\n",
    "        self.Lrd = []\n",
    "        self.Lof = []\n",
    "    def calculateEuclidian(self, a, b):\n",
    "        return np.sum(np.square(a-b))**(0.5)\n",
    "    def calculateKthDistance(self):\n",
    "        # calculating kth distance and kNN for every point\n",
    "        for i in range(len(self.dataSet)):\n",
    "            distanceArray = []\n",
    "            for j in range(len(self.dataSet)):\n",
    "                distanceArray.append(self.calculateEuclidian(i, j))\n",
    "            # distanceArray = (np.sum((self.dataSet-self.dataSet[i])**2, axis = 1))**0.5\n",
    "            indices = np.argsort(distanceArray)[1:self.k+1]\n",
    "            temp2 = []\n",
    "            for j in indices:\n",
    "                temp2.append([distanceArray[j],j])\n",
    "            self.kNearestNbrs.append(temp2)\n",
    "            # print(temp2[-1])\n",
    "            # self.kThDistance.append(distanceArray[indices[self.k-1]]) #because first will be the point itself.\n",
    "            self.kThDistance.append(temp2[-1][0])\n",
    "    def reachDistance(self, i, j):\n",
    "        return max(self.calculateEuclidian(self.dataSet[i], self.dataSet[j]), self.kThDistance[j])\n",
    "    def calculateLRD(self):\n",
    "        for i in range(len(self.dataSet)):\n",
    "            s = 0\n",
    "            for point in self.kNearestNbrs[i]:\n",
    "                s = s + self.reachDistance(i, point[1])\n",
    "            s = s/self.k\n",
    "            self.Lrd.append(1/s)\n",
    "    def calculateLOF(self):\n",
    "        for i in range(len(self.dataSet)):\n",
    "            # print(i)\n",
    "            lofOfPoint = 0\n",
    "            for point in self.kNearestNbrs[i]:\n",
    "                lofOfPoint = lofOfPoint + self.Lrd[point[1]]\n",
    "            lofOfPoint = lofOfPoint/self.Lrd[i]\n",
    "            lofOfPoint = lofOfPoint/self.k\n",
    "            self.Lof.append(lofOfPoint)\n",
    "        self.Lof = np.array(self.Lof)\n",
    "    def algorithim(self):\n",
    "        self.calculateKthDistance()\n",
    "        self.calculateLRD()\n",
    "        self.calculateLOF()\n",
    "        # print(self.Lof)\n",
    "tester = LOF(dataSet, 4)\n",
    "tester.algorithim()\n",
    "print(np.mean(tester.Lof))\n",
    "print(np.max(tester.Lof))\n",
    "print(tester.Lof.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otsu Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers are  14\n",
      "Threshold is  1.228697504564006\n"
     ]
    }
   ],
   "source": [
    "from math import ceil, floor\n",
    "class Otsu:\n",
    "    def __init__(self, OutlierScores, noOfBins):\n",
    "        self.OutlierScores = OutlierScores\n",
    "        self.noOfBins = noOfBins\n",
    "        self.threshHold = 0\n",
    "        self.bins = {}\n",
    "\n",
    "    def dividingLbins(self):\n",
    "        indices = np.argsort(self.OutlierScores)\n",
    "        maxValue = np.max(self.OutlierScores)\n",
    "        minValue = np.min(self.OutlierScores)\n",
    "        # self.bins = {}\n",
    "        # for i in range(self.noOfBins+1):\n",
    "        #     self.bins[i] = []\n",
    "        # binWidth = (maxValue-minValue)/self.noOfBins\n",
    "        # print(maxValue)\n",
    "        # print(minValue)\n",
    "        # print(binWidth)\n",
    "        # print(binss)\n",
    "        # print(binEdges)\n",
    "        # for i in range(len(self.OutlierScores)):\n",
    "        #     binNumber = floor((self.OutlierScores[i]-minValue)/binWidth) \n",
    "        #     self.bins[binNumber].append([self.OutlierScores[i], i]) \n",
    "        # for i in range(self.noOfBins):\n",
    "        #     print(\"BinNumber is \", i, \"number of points are \", len(self.bins[i]))   \n",
    "    def calculatingT(self):\n",
    "        minWVar = 1000000\n",
    "        self.threshHold = 0\n",
    "        # noOfOutliers  = 0\n",
    "        binss, binEdges = np.histogram(self.OutlierScores, bins = self.noOfBins)\n",
    "        # print(binss)\n",
    "        # print(binEdges)\n",
    "        ooo = 0\n",
    "        minVar = 100000\n",
    "        for t in range(1, self.noOfBins):\n",
    "            Inliers = np.sum(binss[:t])\n",
    "            Outliers = np.sum(binss[t:])\n",
    "            Wo = Inliers/(Inliers+Outliers)\n",
    "            W1 = Outliers/(Inliers+Outliers)\n",
    "            WoMean = 0\n",
    "            W1Mean = 0\n",
    "            for i in range(t):\n",
    "                WoMean = WoMean + binss[i]*(binEdges[i]+binEdges[i+1])/2\n",
    "            for i in range(t, self.noOfBins):\n",
    "                W1Mean = W1Mean + binss[i]*(binEdges[i]+binEdges[i+1])/2\n",
    "            WoMean = WoMean/(Inliers)\n",
    "            W1Mean= W1Mean/(Outliers)\n",
    "            WoVar = W1Var = 0\n",
    "            for i in range(t):\n",
    "                d= (((binEdges[i]+binEdges[i+1])/2)-WoMean)**2 \n",
    "                WoVar = WoVar + d*binss[i]\n",
    "            for i in range(t, self.noOfBins):\n",
    "                d= (((binEdges[i]+binEdges[i+1])/2)-W1Mean)**2 \n",
    "                W1Var = W1Var + d*binss[i]\n",
    "            WoVar = WoVar/(Inliers)\n",
    "            W1Var = W1Var/(Outliers)\n",
    "            var = Wo*WoVar + W1Var*W1\n",
    "            if(var < minVar):\n",
    "                minVar = var\n",
    "                ooo = Outliers\n",
    "                self.threshHold = (binEdges[t]+binEdges[t+1])/2\n",
    "        print(\"Number of outliers are \",ooo)\n",
    "        print(\"Threshold is \",self.threshHold)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "otsuTester = Otsu(tester.Lof, 60)\n",
    "otsuTester.dividingLbins()\n",
    "otsuTester.calculatingT()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1d19c08c163913efebb1b2f5cc346864d85551cf62eeb6ed1ec53a6678f2dc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
